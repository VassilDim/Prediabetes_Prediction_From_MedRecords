{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96faa18",
   "metadata": {},
   "source": [
    "# 2. Read Data from SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083e03e3",
   "metadata": {},
   "source": [
    "**RECAP:** 12 output directories contain 1,000,000 - 6,000,000 entries per tables for patient information, allergies, encounters, medications, conditions, careplans, immunizations, procedures and observations parsed from json files following the FIHR convention for medical records. These tables were imported in a SQL database (prediabetes). Each imported table was cleaned from faulty entries. The clean tables were merged into one single table per category in SQL: patient, allergies, careplans, conditions, immunizations, medications, procedures. Note that observations was not processed in SQL as the table was too large to handle. In addition, encounters tables were not processed as this information is redundant with the information present in the other tables.  \n",
    "This notebook reads the SQL tables and modifies them in order to obtain dataframes in a format and with values allowing model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461f67a",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54aa55",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a513719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198bf08",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c43c5",
   "metadata": {},
   "source": [
    "<a id='load_sql'></a> Define a function that imports as a pandas dataframe a table from a SQL database: **`load_sql_table`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd0c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read table from mysql:\n",
    "def load_sql_table (sql_table, databs = 'prediabetes'):\n",
    "    # Establish a connection to the MySQL database\n",
    "    conn = mysql.connector.connect (\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        password = 'DrVassil08.2018',\n",
    "        database = databs\n",
    "    )\n",
    "    # Define SQL query\n",
    "    query = 'SELECT * FROM {}'.format(sql_table)\n",
    "    # Read table in df\n",
    "    df = pd.read_sql (query, conn)\n",
    "    # close connection\n",
    "    conn.close()\n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b16ebd",
   "metadata": {},
   "source": [
    "<a id='pivot'></a>Define a function **`pivot_L_table`** that rearranges a pandas dataframe to get for each index the categories within a specific column to appear as separate columns in a new dataframe and the values of a third column to populate the new dataframe. In the new dataframe one aims to get a specific value for each category per patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730fef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Large table:\n",
    "\n",
    "def pivot_L_table (df, cols, vals, idx = 'patient_id', batch_size = 10000):\n",
    "    \n",
    "    batch_size = min(batch_size, len(df))  # Adjust batch size dynamically\n",
    "    \n",
    "    # Define a dataframe place holder\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the DataFrame in batches\n",
    "    while len(df) > 0:\n",
    "        \n",
    "        batch = df[:batch_size]\n",
    "\n",
    "        # Create a pivot table for the current batch\n",
    "        pivot_table = batch.pivot_table(\n",
    "            index = idx,\n",
    "            columns = cols,\n",
    "            values = vals,\n",
    "            aggfunc = 'sum',\n",
    "            fill_value = 0\n",
    "        )\n",
    "\n",
    "        # Append the pivot table to the result DataFrame\n",
    "        result = pd.concat([result, pivot_table], axis=0)\n",
    "\n",
    "        # Delete the processed rows from the original DataFrame\n",
    "        df = df[batch_size:]\n",
    "    # Reset the index to make patient_id a column again\n",
    "    result['patient_id'] = result.index\n",
    "    result.reset_index(drop = True, inplace = True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783dfdff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738d1e4",
   "metadata": {},
   "source": [
    "## Read tables, tidy (exclude unnecessary columns) and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e3b8e",
   "metadata": {},
   "source": [
    "Read tables as pandas dataframes [directly](#load_sql) from SQL database. Where applicable, pivot the table as described [above](#pivot). Remove columns deemed unnecessary. Save the processed table in *pickle* format for future processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356078b9",
   "metadata": {},
   "source": [
    "### Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19ccd7",
   "metadata": {},
   "source": [
    "Load *patients* table from SQL database. Note that a lot of the information from that table is not kept such as address, driver's license. In fact, much of the information that is kept will be removed as well later on during the processing steps. The dataframe is saved as a `.pkl` file (takes less memory) for future processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read patients table\n",
    "patients = load_sql_table ('patients')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "patients_df = patients[['patient_id', 'marital', 'race', 'ethnicity', 'gender']]\n",
    "\n",
    "# Save the patients_df as a pickle table\n",
    "patients_df.to_pickle('patients_df.pkl')\n",
    "\n",
    "# Remove dataframe to liberate memory\n",
    "del patients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba59c94",
   "metadata": {},
   "source": [
    "### Allergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read allergies data set (allegies_ds) table\n",
    "allergies_df = load_sql_table ('allegies_ds')\n",
    "\n",
    "# Check for duplicated rows\n",
    "allergies_df[allergies_df.duplicated()].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c17d22",
   "metadata": {},
   "source": [
    " The *allergies* dataframe contains no duplicates.  \n",
    " Obtain one-hot-encoded allergies table (i.e. dummy variables for each allergy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffb31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode allergies for every patient\n",
    "description_allergy_1hot = pd.get_dummies (allergies_df['description_allergy'])\n",
    "\n",
    "# Concatinate the one-hot encoding to patient_id's:\n",
    "allergies_df_1hot_ = pd.concat (\n",
    "    [allergies_df['patient_id'], \n",
    "     description_allergy_1hot],\n",
    "    axis = 1\n",
    ")\n",
    "allergies_df_1hot_\n",
    "\n",
    "# Group by patient_id and sum the one-hot encoded columns\n",
    "allergies_df_1hot = allergies_df_1hot_.groupby ('patient_id').sum().reset_index()\n",
    "\n",
    "# Clean up to save memory\n",
    "del allergies_df, description_allergy_1hot, allergies_df_1hot_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6987e6",
   "metadata": {},
   "source": [
    "Save 1-hot-encoded allergies table to a picke file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e23acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save one-hot encoded dataframe in pickle format:\n",
    "allergies_df_1hot.to_pickle ('allergies_df_1hot.pkl')\n",
    "\n",
    "# Clean up to save memory\n",
    "del allergies_df_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95baf2b7",
   "metadata": {},
   "source": [
    "### Careplans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7dde89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4558/3234992038.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql (query, conn)\n"
     ]
    }
   ],
   "source": [
    "df = load_sql_table('careplans_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50fb405",
   "metadata": {},
   "source": [
    "Calculate the total duration of careplan for each patient. For instance, if a patient has undergone careplan1 for 10 days in 2018 and 5 days in 2019, the total value for that careplan would be 15 days. The value is in days. Then, pivot table to obtain a single patient for each row and careplan for each column with values indicating the sum of careplan duration in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f12d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['patient_id', 'careplan_n_reason'])['careplan_duration'].sum()\n",
    "\n",
    "# Pivot the grouped DataFrame\n",
    "pivot_table = grouped_df.reset_index().pivot(index='patient_id', \n",
    "                                             columns='careplan_n_reason', \n",
    "                                             values='careplan_duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e03df1c",
   "metadata": {},
   "source": [
    "Upon pivoting, there will be many patients with NaN for many careplans. The null values will be replaced with **0** indicating the patient has not undergone a single day of the specific careplan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f0066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0\n",
    "pivot_table.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save table\n",
    "pivot_table.to_pickle ('careplans_df.pkl')\n",
    "\n",
    "# Clean up to save memory\n",
    "del pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884689bc",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5ec72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read conditions data set (conditions_ds) table\n",
    "conditions_df = load_sql_table ('conditions_ds')\n",
    "\n",
    "# Pivot table\n",
    "df = pivot_L_table (df = conditions_df, \n",
    "               cols = 'condition_description', \n",
    "               vals = 'condition_duration'\n",
    "               )\n",
    "\n",
    "# Clean up to save memory\n",
    "del conditions_df\n",
    "\n",
    "# Replace NaN with 0\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "# Group for each patient\n",
    "df = df.groupby ('patient_id').sum()\n",
    "\n",
    "# Save final table\n",
    "df.to_pickle ('conditions_df.pkl')\n",
    "\n",
    "# Clean up to save memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f59bcf",
   "metadata": {},
   "source": [
    "### Immunizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc5fd3",
   "metadata": {},
   "source": [
    "<a id='immunizations'></a>For the immunizations table, days since last immunization type will be calculated. For the sake of simplicity, only the last immunization date will be considered for this engineered feature. The patient that did not get specific immunization will have NaN values, which will be replaced with the equivalent of 80 years in days (reasonable life expectancy) since last immunization type. This would be the equivalent of no immunization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc17dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read conditions data set (conditions_ds) table\n",
    "df = load_sql_table ('immunizations_ds')\n",
    "\n",
    "# Sort by days since\n",
    "df_sort = df.sort_values ('days_since_immunization')\n",
    "\n",
    "del df\n",
    "\n",
    "# Keep only the first row (latest) for each 'patient_id'\n",
    "result = df_sort.groupby('patient_id').first().reset_index()\n",
    "\n",
    "del df_sort\n",
    "\n",
    "# Pivot the grouped DataFrame\n",
    "df = result.pivot(index='patient_id',\n",
    "                  columns='immunization_description',\n",
    "                  values='days_since_immunization')\n",
    "\n",
    "# Clean up:\n",
    "del result\n",
    "\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "# Replace the NaN (no immunization) with numbeer of days for 80 years\n",
    "df.fillna (int(80*365), inplace = True)\n",
    "\n",
    "# Save cleaned up dataframe\n",
    "df.to_pickle ('immunizations_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bb5d8",
   "metadata": {},
   "source": [
    "### Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68afe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read medications data set (medications_ds) table\n",
    "df = load_sql_table ('medications_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984126a5",
   "metadata": {},
   "source": [
    "All medication entries related to *prediabetes* and *diabetes* will be removed for obvious reasons (i.e. if a patient is taking a medication for diabetes, it implies the patient has been diagnosed with the diabetes and has potentially already passed through the prediabetes stage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all entries of medication for diabetes\n",
    "df_filtered = df[~df['medication_reason'].str.contains('diabetes|prediabetes', case=False)]\n",
    "\n",
    "# Drop medication_reason\n",
    "df_filtered.drop ('medication_reason', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63955c5a",
   "metadata": {},
   "source": [
    "The medications engineered feature here will be total days under a specific medication. Upon pivoting the table, many patients will have null values for a variety of medications indicating they were never on the corresponding medication. These null values will be replaced with 0 (i.e. patient has never taken the medication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table to get days of medication for each medication per patient_id\n",
    "df = pivot_L_table (df = df_filtered, \n",
    "                    cols = 'medication', \n",
    "                    vals = 'days_on_medication', \n",
    "                    idx = 'patient_id', batch_size = 5000)\n",
    "\n",
    "# Save cleaned up dataframe\n",
    "df.to_pickle ('medications_df.pkl')\n",
    "\n",
    "# Clean up:\n",
    "del df_filtered\n",
    "\n",
    "# Replace NaN with 0\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "# Group for each patient\n",
    "df_final = df.groupby ('patient_id').sum()\n",
    "\n",
    "# Clean up:\n",
    "del df\n",
    "\n",
    "# Re-create patient_id column\n",
    "df_final['patient_id'] = df_final.index\n",
    "\n",
    "# Save table\n",
    "df_final.to_pickle ('medications_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d665e5",
   "metadata": {},
   "source": [
    "### Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035789a",
   "metadata": {},
   "source": [
    "Same reasoning will be followed for *procedures* as for *immunizations* [above](#immunizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read medications data set (medications_ds) table\n",
    "df = load_sql_table ('procedures_ds')\n",
    "\n",
    "# Pivot table to get days since procedure for each procedure per patient_id\n",
    "df_pivot = pivot_L_table (df = df, \n",
    "                    cols = 'procedure_description', \n",
    "                    vals = 'days_since_procedure', \n",
    "                    idx = 'patient_id', batch_size = 5000)\n",
    "\n",
    "# Clean up memory\n",
    "del df\n",
    "\n",
    "# Replace NaN with 0\n",
    "df_pivot.fillna(0, inplace = True)\n",
    "\n",
    "# Group for each patient\n",
    "df_final = df_pivot.groupby ('patient_id').sum()\n",
    "\n",
    "# Clean up:\n",
    "del df_pivot\n",
    "\n",
    "# Save cleaned up dataframe\n",
    "df_final.to_pickle ('procedures_df.pkl')\n",
    "\n",
    "# Read table:\n",
    "df_final = pd.read_pickle ('procedures_df.pkl')\n",
    "\n",
    "df_final\n",
    "\n",
    "# Reset the index to make 'patient_id' a column again\n",
    "df_final['patient_id'] = df_final.index\n",
    "\n",
    "df_final.to_pickle ('procedures_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3ac58",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58625e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
